{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reconhecimento Facial OpenCV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mgrinet/reconhecimento-facial-openCV/blob/master/Reconhecimento_Facial_OpenCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAmIIVvx1C_H",
        "colab_type": "text"
      },
      "source": [
        "## O que é Detecção Facial?\n",
        "A detecção de rosto é um tipo de tecnologia de visão computacional capaz de identificar os rostos das pessoas nas imagens digitais. Isso é muito fácil para humanos, mas os computadores precisam de instruções precisas. As imagens podem conter muitos objetos que não são rostos humanos, como prédios, carros, animais e assim por diante.\n",
        "\n",
        "É diferente de outras tecnologias de visão computacional que envolvem rostos humanos, como reconhecimento facial, análise e rastreamento.\n",
        "\n",
        "O **reconhecimento facial** envolve a identificação do rosto na imagem como pertencente à pessoa X e não à pessoa Y. É frequentemente usado para fins biométricos, como desbloquear seu smartphone.\n",
        "\n",
        "A **análise facial** tenta entender algo sobre as pessoas a partir de suas características faciais, como determinar sua idade, sexo ou a emoção que elas estão exibindo.\n",
        "\n",
        "O **rastreamento facial** está presente principalmente na análise de vídeo e tenta seguir um rosto e seus recursos (olhos, nariz e lábios) de quadro a quadro. Os aplicativos mais populares são vários filtros disponíveis em aplicativos móveis como o Snapchat.\n",
        "\n",
        "Todos esses problemas têm diferentes soluções tecnológicas. Este tutorial se concentrará em uma solução tradicional para o primeiro desafio: **detecção facial**.\n",
        "\n",
        "## O que são Features?\n",
        "Uma fatureé uma informação em uma imagem que é relevante para resolver um determinado problema. Pode ser algo tão simples quanto um valor de pixel único ou mais complexo, como arestas (edges), cantos (corners) e formas. Você pode combinar várias features simples em uma feature complexa.\n",
        "\n",
        "A aplicação de determinadas operações a uma imagem produz informações que também podem ser consideradas features. A visão computacional e o processamento de imagens têm uma grande coleção de features úteis e operações de extração de features.\n",
        "\n",
        "Basicamente, qualquer propriedade inerente ou derivada de uma imagem pode ser usada como uma featurepara resolver tarefas.\n",
        "\n",
        "\n",
        "## Estrutura de detecção de objetos Viola-Jones\n",
        "Esse algoritmo recebeu o nome de dois pesquisadores de visão computacional que propuseram o método em 2001: **Paul Viola e Michael Jones**.\n",
        "\n",
        "Eles desenvolveram uma estrutura geral de detecção de objetos que foi capaz de fornecer taxas competitivas de detecção de objetos em tempo real. Ele pode ser usado para resolver uma variedade de problemas de detecção, mas a principal motivação vem da detecção de rosto.\n",
        "\n",
        "O algoritmo Viola-Jones possui quatro etapas principais e você aprenderá mais sobre cada uma delas nas seções a seguir:\n",
        "\n",
        "**Selecionando recursos semelhantes ao Haar\n",
        "**Criando uma imagem integral\n",
        "**Executando o treinamento AdaBoost\n",
        "**Criando cascatas de classificadores\n",
        "Dada uma imagem, o algoritmo analisa muitas sub-regiões menores e tenta encontrar um rosto procurando recursos específicos em cada sub-região. Ele precisa verificar várias posições e escalas diferentes, porque uma imagem pode conter muitas faces de vários tamanhos. Viola e Jones usavam recursos do tipo Haar para detectar rostos.\n",
        "\n",
        "## Features tipo Haar\n",
        "Todos os rostos humanos compartilham algumas semelhanças. Se você olhar para uma fotografia mostrando o rosto de uma pessoa, verá, por exemplo, que a região dos olhos é mais escura que a ponte do nariz. As bochechas também são mais brilhantes que a região dos olhos. Podemos usar essas propriedades para nos ajudar a entender se uma imagem contém um rosto humano.\n",
        "\n",
        "Uma maneira simples de descobrir qual região é mais clara ou mais escura é resumir os valores de pixel de ambas as regiões e compará-los. A soma dos valores de pixel na região mais escura será menor que a soma de pixels na região mais clara. Isso pode ser realizado usando features tipo Haar.\n",
        "\n",
        "Uma feature tipo Haar é representada pegando uma parte retangular de uma imagem e dividindo esse retângulo em várias partes. Eles são frequentemente visualizados como retângulos adjacentes em preto e branco:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYKqznOR1NEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "0 0 0 0       0 1 1 0      0 1 1 0       1 1 0 0 \n",
        "1 1 1 1       0 1 1 0      0 1 1 0       0 0 1 1 \n",
        "0 0 0 0       0 1 1 0      0 1 1 0       0 0 1 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTo3AcSx1Orz",
        "colab_type": "text"
      },
      "source": [
        "4 tipos básicos de features tipo Haar:\n",
        "\n",
        "**Recurso horizontal com dois retângulos\n",
        "**Recurso vertical com dois retângulos\n",
        "**Recurso vertical com três retângulos\n",
        "**Recurso diagonal com quatro retângulos\n",
        "Os dois primeiros exemplos são úteis para detectar arestas. O terceiro detecta linhas e o quarto é bom para encontrar recursos diagonais. Mas como eles funcionam?\n",
        "O valor do recurso é calculado como um número único: a soma dos valores de pixel na área preta menos a soma dos valores de pixel na área branca. Para áreas uniformes como uma parede, esse número seria próximo de zero e não fornecerá nenhuma informação significativa.\n",
        "\n",
        "Para ser útil, um recurso semelhante ao Haar precisa fornecer um grande número, o que significa que as áreas nos retângulos em preto e branco são muito diferentes. Existem recursos conhecidos que funcionam muito bem para detectar rostos humanos:\n",
        "\n",
        "## Imagens integrais\n",
        "Uma imagem integral (também conhecida como tabela de área somada) é o nome de uma estrutura de dados e de um algoritmo usado para obter essa estrutura de dados. É usado como uma maneira rápida e eficiente de calcular a soma dos valores de pixel em uma imagem ou parte retangular de uma imagem.\n",
        "\n",
        "Em uma imagem integral, o valor de cada ponto é a soma de todos os pixels acima e à esquerda, incluindo o pixel de destino:\n",
        "\n",
        "![](https://files.realpython.com/media/Integral_image.ff570b17c188.png)\n",
        "\n",
        "Cálculo de uma imagem integral a partir dos valores de pixel\n",
        "Cálculo de uma imagem integral a partir dos valores de pixel\n",
        "A imagem integral pode ser calculada em uma única passagem sobre a imagem original. Isso reduz a soma das intensidades de pixel dentro de um retângulo em apenas três operações com quatro números, independentemente do tamanho do retângulo:\n",
        "\n",
        "![](https://files.realpython.com/media/ABCD.97ca0ef04d39.png)\n",
        "\n",
        "\n",
        "Selecionando um retângulo em uma imagem integral\n",
        "Calcule a soma de pixels no retângulo laranja.\n",
        "A soma dos pixels no retângulo ABCD pode ser derivada dos valores dos pontos A, B, C e D, usando a fórmula D - B - C + A. É mais fácil entender visualmente esta fórmula:\n",
        "\n",
        "![](https://files.realpython.com/media/ABCD-2.c181d3f76349.png)\n",
        "\n",
        "Cálculo passo a passo de um retângulo em uma imagem integral\n",
        "Cálculo da soma de pixels passo a passo\n",
        "Você notará que subtrair B e C significa que a área definida com A foi subtraída duas vezes, por isso precisamos adicioná-la novamente.\n",
        "\n",
        "Agora você tem uma maneira simples de calcular a diferença entre as somas dos valores de pixel de dois retângulos. Isso é perfeito para recursos do tipo Haar!\n",
        "\n",
        "Mas como você decide quais desses recursos e em quais tamanhos usar para encontrar rostos nas imagens? Isso é resolvido por um algoritmo de aprendizado de máquina chamado boosting. Especificamente, você aprenderá sobre o AdaBoost, abreviação de Adaptive Boosting.\n",
        "\n",
        "## AdaBoost\n",
        "O impulso é baseado na seguinte pergunta: “Um conjunto de alunos fracos pode criar um único aluno forte?” Um aluno fraco (ou classificador fraco) é definido como um classificador que é apenas um pouco melhor do que a adivinhação aleatória.\n",
        "\n",
        "Na detecção de faces, isso significa que um aluno fraco pode classificar uma sub-região de uma imagem como uma face ou não, apenas um pouco melhor do que a adivinhação aleatória. Um aluno forte é substancialmente melhor ao escolher rostos de não rostos.\n",
        "\n",
        "O poder de impulsionar vem da combinação de muitos (milhares) de classificadores fracos em um único classificador forte. No algoritmo Viola-Jones, cada recurso do tipo Haar representa um aluno fraco. Para decidir o tipo e tamanho de um recurso que entra no classificador final, o AdaBoost verifica o desempenho de todos os classificadores que você fornece a ele.\n",
        "\n",
        "Para calcular o desempenho de um classificador, você o avalia em todas as sub-regiões de todas as imagens usadas para treinamento. Algumas sub-regiões produzirão uma forte resposta no classificador. Esses serão classificados como positivos, o que significa que o classificador acha que ele contém um rosto humano.\n",
        "\n",
        "As sub-regiões que não produzem uma resposta forte não contêm um rosto humano, na opinião dos classificadores. Eles serão classificados como negativos.\n",
        "\n",
        "Os classificadores que tiveram bom desempenho recebem maior importância ou peso. O resultado final é um classificador forte, também chamado de classificador otimizado, que contém os classificadores fracos com melhor desempenho.\n",
        "\n",
        "O algoritmo é chamado de adaptativo porque, à medida que o treinamento avança, dá mais ênfase às imagens que foram classificadas incorretamente. Os classificadores fracos que têm melhor desempenho nesses exemplos difíceis são mais pesados do que outros.\n",
        "\n",
        "## Exemplo:\n",
        "\n",
        "Exemplo de recursos para classificar com o **AdaBoost**\n",
        "\n",
        "![](https://files.realpython.com/media/AdaBoost-1.f0eacdf0c2e2.png)\n",
        "\n",
        "Os círculos azul e laranja são amostras que pertencem a diferentes categorias.\n",
        "Imagine que você deve classificar círculos azuis e laranja na imagem a seguir usando um conjunto de classificadores fracos:\n",
        "\n",
        "\n",
        "![](https://files.realpython.com/media/AdaBoost-2.03c3c6a0c34f.png)\n",
        "\n",
        "Primeiro classificador no exemplo do **AdaBoost**\n",
        "O primeiro classificador fraco classifica alguns dos círculos azuis corretamente.\n",
        "O primeiro classificador usado captura alguns dos círculos azuis, mas perde os outros. Na próxima iteração, você dará mais importância aos exemplos perdidos:\n",
        "\n",
        "\n",
        "![](https://files.realpython.com/media/AdaBoost-3.2d874993bc92.png)\n",
        "\n",
        "Alterando a importância das amostras no exemplo do **AdaBoost**\n",
        "As amostras azuis perdidas recebem mais importância, indicadas pelo tamanho.\n",
        "O segundo classificador que conseguir classificar corretamente esses exemplos terá um peso maior. Lembre-se, se um classificador fraco tiver um desempenho melhor, ele terá um peso maior e, portanto, maiores chances de ser incluído nos classificadores finais fortes:\n",
        "\n",
        "\n",
        "\n",
        "![](https://files.realpython.com/media/AdaBoost-4.705558b218f3.png)\n",
        "\n",
        "Segundo classificador no exemplo do **AdaBoost**\n",
        "O segundo classificador captura os círculos azuis maiores.\n",
        "Agora você conseguiu capturar todos os círculos azuis, mas capturou incorretamente alguns dos círculos laranja. Esses círculos laranja classificados incorretamente recebem mais importância na próxima iteração:\n",
        "\n",
        "![](https://files.realpython.com/media/AdaBoost-5.1d800ca4ffff.png)\n",
        "\n",
        "Alterando a importância das amostras no exemplo do **AdaBoost**\n",
        "Os círculos laranja classificados incorretamente recebem mais importância e outros são reduzidos.\n",
        "O classificador final consegue capturar os círculos laranja corretamente:\n",
        "\n",
        "\n",
        "![](https://files.realpython.com/media/AdaBoost-6.ac0a9accb5f7.png)\n",
        "\n",
        "Terceiro classificador no exemplo do **AdaBoost**\n",
        "O terceiro classificador captura os círculos laranja restantes.\n",
        "Para criar um classificador forte, você combina os três classificadores para classificar corretamente todos os exemplos:\n",
        "\n",
        "Classificador final e forte no exemplo do **AdaBoost**\n",
        "\n",
        "\n",
        "![](https://files.realpython.com/media/AdaBoost-7.2ec2db197252.png)\n",
        "\n",
        "Usando uma variação desse processo, Viola e Jones avaliaram centenas de milhares de classificadores especializados em encontrar rostos em imagens. Mas seria computacionalmente caro executar todos esses classificadores em todas as regiões e em todas as imagens; portanto, eles criaram algo chamado cascata de classificadores.\n",
        "\n",
        "## Classificadores em cascata\n",
        "A definição de cascata é uma série de cachoeiras que se sucedem. Um conceito semelhante é usado na ciência da computação para resolver um problema complexo com unidades simples. O problema aqui é reduzir o número de cálculos para cada imagem.\n",
        "\n",
        "Para resolvê-lo, Viola e Jones transformaram seu classificador forte (consistindo em milhares de classificadores fracos) em uma cascata onde cada classificador fraco representa um estágio. O trabalho da cascata é descartar rapidamente as não faces e evitar desperdiçar tempo e cálculos preciosos.\n",
        "\n",
        "Quando uma sub-região de imagem entra em cascata, ela é avaliada pelo primeiro estágio. Se esse estágio avalia a sub-região como positiva, o que significa que ele é um rosto, o resultado do estágio é talvez.\n",
        "\n",
        "Se uma sub-região recebe um talvez, ela é enviada para o próximo estágio da cascata. Se esse fizer uma avaliação positiva, talvez seja outro, e a imagem será enviada para o terceiro estágio:\n",
        "\n",
        "![](https://files.realpython.com/media/one_stage.901b5d130118.png)\n",
        "\n",
        "Um único classificador em cascata\n",
        "Um classificador fraco em cascata\n",
        "Esse processo é repetido até que a imagem passe por todas as etapas da cascata. Se todos os classificadores aprovarem a imagem, ela será finalmente classificada como um rosto humano e apresentada ao usuário como uma detecção.\n",
        "\n",
        "Se, no entanto, a primeira etapa der uma avaliação negativa, a imagem será imediatamente descartada por não conter um rosto humano. Se passar no primeiro estágio, mas falhar no segundo estágio, também será descartado. Basicamente, a imagem pode ser descartada em qualquer estágio do classificador:\n",
        "\n",
        "![](https://files.realpython.com/media/Classifier_cascade.e3b2a5652044.png)\n",
        "\n",
        "Classificadores em cascata para detecção de rosto\n",
        "Uma cascata de classificadores _n_ para detecção de rosto\n",
        "Isso foi projetado para que as não-faces sejam descartadas muito rapidamente, o que economiza muito tempo e recursos computacionais. Como todo classificador representa um recurso de um rosto humano, uma detecção positiva basicamente diz: \"Sim, essa sub-região contém todos os recursos de um rosto humano\". Mas, assim que um recurso está ausente, ele rejeita toda a sub-região.\n",
        "\n",
        "Para isso, é importante colocar os classificadores com melhor desempenho no início da cascata. No algoritmo Viola-Jones, os classificadores de ponte de olhos e nariz são exemplos de classificadores fracos com melhor desempenho.\n",
        "\n",
        "Agora que você entende como o algoritmo funciona, é hora de usá-lo para detectar rostos com o Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myqz-PK4yU3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import sys\n",
        "\n",
        "cascPath = sys.argv[1]\n",
        "faceCascade = cv2.CascadeClassifier(cascPath)\n",
        "\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # capturar frame por frame\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = faceCascade.detectMultiScale(\n",
        "        gray,\n",
        "        scaleFactor=1.1,\n",
        "        minNeighbors=5,\n",
        "        minSize=(30, 30),\n",
        "        flags=cv2.cv.CV_HAAR_SCALE_IMAGE\n",
        "    )\n",
        "\n",
        "    # Desenhar retangulo nas faces\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "    # Mostrar o frame capturado\n",
        "    cv2.imshow('Video', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Liberar a captura quando finalizar\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}